{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekwEPS9C9ngs"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp-Z_fFCDrWJ",
        "outputId": "7ea4e055-f263-4ee3-bdc7-67ece7c9bed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras<3.0.0\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting mediapipe-model-maker\n",
            "  Downloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.4.0)\n",
            "Collecting mediapipe>=0.10.0 (from mediapipe-model-maker)\n",
            "  Downloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.10.0.84)\n",
            "Collecting tensorflow<2.16,>=2.10 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting tensorflow-addons (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.9.6)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.16.1)\n",
            "Collecting tensorflow-model-optimization<0.8.0 (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Collecting tensorflow-text (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tf-models-official<2.16.0,>=2.13.2 (from mediapipe-model-maker)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (3.7.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe>=0.10.0->mediapipe-model-maker) (4.10.0.84)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe>=0.10.0->mediapipe-model-maker)\n",
            "  Downloading sounddevice-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (4.12.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.64.1)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.10->mediapipe-model-maker)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization<0.8.0->mediapipe-model-maker) (0.1.8)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.0.11)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (10.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.137.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.2.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.6.17)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.10.0.84)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.0.8)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.0.2)\n",
            "Collecting sacrebleu (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.13.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n",
            "Collecting seqeval (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorflow-text (from mediapipe-model-maker)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.1.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub->mediapipe-model-maker) (2.17.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->mediapipe-model-maker)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (8.1.7)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (16.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (2.32.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (4.66.5)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (1.9.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.44.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (2024.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->mediapipe-model-maker) (3.20.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (6.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.10)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (1.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.0.4)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe>=0.10.0->mediapipe-model-maker) (3.1.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (4.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.5.2)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->mediapipe-model-maker) (0.16)\n",
            "INFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets->mediapipe-model-maker)\n",
            "  Downloading tensorflow_metadata-1.16.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker) (1.65.0)\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe>=0.10.0->mediapipe-model-maker) (2.22)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.24.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (5.5.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (1.3.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (2.1.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official<2.16.0,>=2.13.2->mediapipe-model-maker) (1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.10->mediapipe-model-maker) (3.2.2)\n",
            "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe_model_maker-0.2.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mediapipe-0.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.0-py3-none-any.whl (32 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=4646beabc5ac9d13912e85589c70a48a6b77ee9484d3a486d5d910f7652fbb46\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: wrapt, typeguard, tensorflow-model-optimization, tensorflow-estimator, protobuf, portalocker, ml-dtypes, keras, colorama, tensorflow-addons, sounddevice, sacrebleu, tensorflow-metadata, seqeval, tensorboard, mediapipe, tensorflow, tf-keras, tensorflow-text, tf-models-official, mediapipe-model-maker\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.15.0\n",
            "    Uninstalling tensorflow-metadata-1.15.0:\n",
            "      Successfully uninstalled tensorflow-metadata-1.15.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 keras-2.15.0 mediapipe-0.10.15 mediapipe-model-maker-0.2.1.4 ml-dtypes-0.3.2 portalocker-2.10.1 protobuf-4.25.5 sacrebleu-2.4.3 seqeval-1.2.2 sounddevice-0.5.0 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.15.0 tensorflow-metadata-1.13.1 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 typeguard-2.13.3 wrapt-1.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install 'keras<3.0.0' mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K57gfRSqHROk"
      },
      "outputs": [],
      "source": [
        "!pip install typeguard>=4.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZw57VAC9z49",
        "outputId": "be3dcdaa-138b-4c33-a8b4-db430f3af73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/vishnukv64/cvcclinicdb\n",
            "License(s): unknown\n",
            "Downloading cvcclinicdb.zip to /content\n",
            "100% 80.3M/80.3M [00:06<00:00, 19.7MB/s]\n",
            "100% 80.3M/80.3M [00:06<00:00, 12.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle/\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d vishnukv64/cvcclinicdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnu3PCAj91qp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c6fd96-65ba-46f2-9888-173f544d6849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace CVC-ClinicDB/Ground_Truth/1.tif? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/cvcclinicdb.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrMnNHGB95oC",
        "outputId": "edf9e159-f02b-439a-c88f-e02beb30b7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install natsort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80DVMoMG98xY",
        "outputId": "fdc60bfc-da75-42f2-ff81-de0ed38ef6b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import natsort\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import glob\n",
        "from PIL import Image\n",
        "import albumentations\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import helper\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbZOcJmY-B73",
        "outputId": "e4fcced0-ebcd-4b84-db4d-8e8a095050d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "612\n",
            "612\n"
          ]
        }
      ],
      "source": [
        "Data_dir_images = \"CVC-ClinicDB/Original\"\n",
        "Data_dir_masks = \"CVC-ClinicDB/Ground_Truth\"\n",
        "\n",
        "\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "batch_size = 2\n",
        "\n",
        "# class_names = [\"polyp\"]\n",
        "\n",
        "images_list = glob.glob(f\"{Data_dir_images}/*\")\n",
        "images_list = natsort.natsorted(images_list, reverse = False)\n",
        "print(len(images_list))\n",
        "masks_list = glob.glob(f\"{Data_dir_masks}/*\")\n",
        "masks_list = natsort.natsorted(masks_list, reverse = False)\n",
        "print(len(masks_list))\n",
        "\n",
        "split=0.1\n",
        "total_size = len(images_list)\n",
        "valid_size = int(split * total_size)\n",
        "test_size = int(split * total_size)\n",
        "\n",
        "train_img, valid_img , train_masks, valid_masks = model_selection.train_test_split(images_list, masks_list, test_size=valid_size, random_state = 42)\n",
        "\n",
        "train_img, test_img , train_masks, test_masks = model_selection.train_test_split(train_img, train_masks, test_size=test_size, random_state = 42)\n",
        "\n",
        "train_img_tunner, valid_img_tunner , train_masks_tunner, valid_masks_tunner = model_selection.train_test_split(images_list, masks_list, test_size=valid_size, random_state = 42)\n",
        "\n",
        "train_img_tunner, test_img_tunner , train_mask_tunners, test_masks_tunner = model_selection.train_test_split(train_img_tunner, train_masks_tunner, test_size=test_size, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data_tunner(images, masks):\n",
        "    final_images, final_masks = list(), list()\n",
        "    for e, item in enumerate(images):\n",
        "        image = cv2.imread(images[e], cv2.IMREAD_GRAYSCALE) # , cv2.IMREAD_GRAYSCALE#we use cv2 because PIL didnt load the image and we convert later to PIL image\n",
        "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        final_images.append(image)\n",
        "\n",
        "        mask = cv2.imread(masks[e], cv2.IMREAD_GRAYSCALE)#we use cv2 because PIL didnt load the image and we convert later to PIL image\n",
        "        # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "        final_masks.append(mask)\n",
        "\n",
        "    return np.array(final_images), np.array(final_masks)"
      ],
      "metadata": {
        "id": "p3B0TVwEQISj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j31klj9p-PJG"
      },
      "outputs": [],
      "source": [
        "train_images_tunner, train_masks_tunner = read_data_tunner(train_img_tunner, train_masks_tunner)\n",
        "valid_images_tunner, valid_masks_tunner = read_data_tunner(valid_img_tunner, valid_masks_tunner)\n",
        "test_images_tunner, test_masks_tunner = read_data_tunner(test_img_tunner, test_masks_tunner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svmeECxF-QHq",
        "outputId": "1224c0d8-64ad-471f-e190-5adddd9c5931"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 288, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_images_tunner.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNvA1HBx-Rle"
      },
      "outputs": [],
      "source": [
        "# converting all mask pixels other than 0 to 1\n",
        "for e,mask in enumerate(train_masks_tunner):\n",
        "    train_masks_tunner[e][train_masks_tunner[e]>0] = 1\n",
        "\n",
        "for e,mask in enumerate(valid_masks_tunner):\n",
        "    valid_masks_tunner[e][valid_masks_tunner[e]>0] = 1\n",
        "\n",
        "for e,mask in enumerate(test_masks_tunner):\n",
        "    test_masks_tunner[e][test_masks_tunner[e]>0] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ2J6SJL-WJ3"
      },
      "outputs": [],
      "source": [
        "# image size\n",
        "SIZE_X = 384\n",
        "SIZE_Y = 288\n",
        "n_classes = 2  # class 1 is background, class 2 is of polyp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTfWs8x_-YER"
      },
      "outputs": [],
      "source": [
        "# adding 3rd dimension for unet model\n",
        "# normalizing image with keras normalizer\n",
        "# it divides each pixel with 255 to change pixel between 0-1\n",
        "#\n",
        "train_images_tunner = np.expand_dims(train_images_tunner, axis=3)\n",
        "# train_images = normalize(train_images, axis=1)\n",
        "\n",
        "valid_images_tunner = np.expand_dims(valid_images_tunner, axis=3)\n",
        "# valid_images = normalize(valid_images, axis=1)\n",
        "\n",
        "test_images_tunner = np.expand_dims(test_images_tunner, axis=3)\n",
        "# test_images = normalize(test_images, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TmhZyRG-ZH4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBjdJx3i-bT5"
      },
      "outputs": [],
      "source": [
        "train_masks_cat_tunner = to_categorical(train_masks_tunner, num_classes=n_classes)\n",
        "test_masks_cat_tunner = to_categorical(test_masks_tunner, num_classes=n_classes)\n",
        "valid_masks_cat_tunner = to_categorical(valid_masks_tunner, num_classes=n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVeZkgop-eMP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import cast\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe0bfxJQ-f-J"
      },
      "outputs": [],
      "source": [
        "def focalLoss(alpha=0.2, gamma=3, rate=0.1, weights=0, bias=0):\n",
        "    def customloss(y_true, y_pred):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "  #     y_pred = tf.cast(y_pred, tf.float64)\n",
        "\n",
        "        # bias = 0\n",
        "        weighted_sum = tf.math.abs(tf.cast(weights*gamma + bias, tf.float32))\n",
        "        # weighted_sum = tf.math.abs(tf.cast(weights*gamma + bias + gamma, tf.float32))\n",
        "        #weighted_sum = tf.math.abs(tf.cast(weights + bias + gamma, tf.float32)) # algo 1\n",
        "        y_predicted = tf.math.abs(tf.nn.sigmoid(weighted_sum))\n",
        "\n",
        "        gamma_d = tf.math.reduce_mean(y_predicted-y_true)\n",
        "        bias_d = tf.math.reduce_mean(y_predicted-y_true)\n",
        "\n",
        "        gamma_ = tf.math.round(gamma - rate * gamma_d)\n",
        "\n",
        "        ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "                labels=y_true, logits=y_pred)\n",
        "        alpha1 = y_true * alpha + (1. - y_true) * (1. - alpha)\n",
        "\n",
        "        pt = tf.where(y_true==1, x=y_pred, y=1-y_pred)\n",
        "        F_loss =  alpha1 * (1. - pt) ** gamma_ * ce\n",
        "        return tf.reduce_mean(F_loss)\n",
        "    return customloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJMuEyPu-pnX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def get_iou_vector(A, B):\n",
        "    t = A>0\n",
        "    p = B>0\n",
        "    intersection = np.logical_and(t,p)\n",
        "    union = np.logical_or(t,p)\n",
        "    iou = (np.sum(intersection) + 1e-10 )/ (np.sum(union) + 1e-10)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def check_units(y_true, y_pred):\n",
        "    if y_pred.shape[1] != 1:\n",
        "      y_pred = y_pred[:,1:2]\n",
        "      y_true = y_true[:,1:2]\n",
        "    return y_true, y_pred\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    y_true, y_pred = check_units(y_true, y_pred)\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    y_true, y_pred = check_units(y_true, y_pred)\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def iou_metric(label, pred):\n",
        "    return tf.numpy_function(get_iou_vector, [label, pred>0.5], tf.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6eDl4Pc-qnE",
        "outputId": "1e5c9a48-e7fe-417b-f15f-412e7cbc72ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.8.30)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rllCOVTA-sl4"
      },
      "outputs": [],
      "source": [
        "import keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_sLSHb5D2Is"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate\n",
        "from keras.layers import Conv2D\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R_bDGGr-v9h"
      },
      "outputs": [],
      "source": [
        "# from keras.layers import Input, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate\n",
        "# from keras.layers.convolutional import Conv2D\n",
        "# from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gsUdjC4-1ne"
      },
      "outputs": [],
      "source": [
        "def base_model(hp):\n",
        "    in_layer = Input(shape=(None, None, 1), dtype='float32', name='input_1')\n",
        "\n",
        "    c1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(in_layer)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c1)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    p1 = MaxPooling2D(pool_size=(2, 2),padding='valid',strides=(2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(p1)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c2)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    p2 = MaxPooling2D(pool_size=(2, 2),padding='valid',strides=(2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(p2)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c3)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    p3 = MaxPooling2D(pool_size=(2, 2),padding='valid',strides=(2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(p3)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c4)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2),padding='valid',strides=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(p4)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c5)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    x5 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    x5 = concatenate([x5,c4], axis=-1)\n",
        "\n",
        "    c6 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(x5)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    x6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    x6 = concatenate([x6,c3], axis=-1)\n",
        "\n",
        "    c7 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(x6)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    x7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    x7 = concatenate([x7,c2], axis=-1)\n",
        "\n",
        "    c8 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(x7)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    x8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    x8 = concatenate([x8,c1], axis=-1)\n",
        "\n",
        "    c9 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(x8)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu')(c9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c10 = Conv2D(filters=2, kernel_size=(1, 1), strides=(1, 1), padding='valid', activation='softmax')(c9)\n",
        "\n",
        "    model = Model(inputs=[in_layer], outputs=[c10])\n",
        "    weights = K.sum(model.get_weights()[0])\n",
        "\n",
        "    hp_gamma = hp.Int('gamma', min_value=1, max_value=9, step=1)\n",
        "    adm = optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss=focalLoss(gamma=hp_gamma, weights=weights), optimizer=adm, metrics=['accuracy',iou_metric,\n",
        "                                                                          metrics.Precision(), metrics.Recall()])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t9BGWCw-3vJ"
      },
      "outputs": [],
      "source": [
        "tuner = keras_tuner.Hyperband(base_model,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=8,\n",
        "                     factor=3,\n",
        "                     directory='/content/Drive/MyDrive/unet_dir',\n",
        "                     project_name='focal_unet_algo1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV8HEM7m-5YO",
        "outputId": "57ca97e2-7cc9-4633-84c6-1068da69d4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 02m 53s]\n",
            "val_loss: 0.0007278262637555599\n",
            "\n",
            "Best val_loss So Far: 0.0007278262637555599\n",
            "Total elapsed time: 00h 22m 38s\n",
            "\n",
            "The hyperparameter search is complete. The  Optimal Gamma\n",
            "is 8.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tuner.search(train_images_tunner,train_masks_cat_tunner,\n",
        "             batch_size=8,\n",
        "             epochs=20,\n",
        "             validation_data=(valid_images_tunner,valid_masks_cat_tunner)\n",
        "             )\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The  Optimal Gamma\n",
        "is {best_hps.get('gamma')}.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9Rq2uDw-8g3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571a9c64-41a4-4fe2-ecac-678baaeccbfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_gamma : 8\n"
          ]
        }
      ],
      "source": [
        "best_gamma = best_hps['gamma']\n",
        "\n",
        "print (f\"best_gamma : {best_gamma}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5eHrx4OAG-U"
      },
      "source": [
        "**Paper 2 code start from Here **"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(images, masks):\n",
        "    final_images, final_masks = list(), list()\n",
        "    for e, item in enumerate(images):\n",
        "        image = cv2.imread(images[e]) # , cv2.IMREAD_GRAYSCALE#we use cv2 because PIL didnt load the image and we convert later to PIL image\n",
        "        image = image/255.\n",
        "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        final_images.append(image)\n",
        "\n",
        "        mask = cv2.imread(masks[e], cv2.IMREAD_GRAYSCALE)#we use cv2 because PIL didnt load the image and we convert later to PIL image\n",
        "        mask = mask/255.\n",
        "        # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "        final_masks.append(mask)\n",
        "\n",
        "    return np.array(final_images), np.array(final_masks)"
      ],
      "metadata": {
        "id": "zR0nq-FMRXAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_masks = read_data(train_img, train_masks)\n",
        "valid_images, valid_masks = read_data(valid_img, valid_masks)\n",
        "test_images, test_masks = read_data(test_img, test_masks)"
      ],
      "metadata": {
        "id": "vlbc64JbRZVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_kZpCR5RdRc",
        "outputId": "302f8c48-db66-4c75-d58b-653578128959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(490, 288, 384, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting all mask pixels other than 0 to 1\n",
        "for e,mask in enumerate(train_masks):\n",
        "    train_masks[e][train_masks[e]>0] = 1\n",
        "\n",
        "for e,mask in enumerate(valid_masks):\n",
        "    valid_masks[e][valid_masks[e]>0] = 1\n",
        "\n",
        "for e,mask in enumerate(test_masks):\n",
        "    test_masks[e][test_masks[e]>0] = 1"
      ],
      "metadata": {
        "id": "7wl1sQCWRgwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oZCFJsLAf3F"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate\n",
        "from keras.layers import Conv2D\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks_cat = to_categorical(train_masks, num_classes=n_classes)\n",
        "test_masks_cat = to_categorical(test_masks, num_classes=n_classes)\n",
        "valid_masks_cat = to_categorical(valid_masks, num_classes=n_classes)"
      ],
      "metadata": {
        "id": "ZZAz9mbRRbHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzIOjoBKA3Sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e8eab6-52bd-4c09-874f-6c0ce4023bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67hpmy2YBCsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b386bb-25b8-4cec-e298-1fa09eba9d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# External libraries\n",
        "from tensorflow.keras.layers import Activation, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Conv1D, UpSampling2D\n",
        "from tensorflow.keras.layers import concatenate, multiply, add, Activation\n",
        "from tensorflow.keras.layers import Input, concatenate\n",
        "# First, import the necessary module\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Focus Gate\n",
        "def FocusGate(input, skip_connections, n_filters, gamma=True, stats='mean', conv_transpose=False):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : gating signal\n",
        "    skip_connections : incoming skip connection to be refined\n",
        "    n_filters : number of filters\n",
        "    gamma : whether to apply non-linear attention. Gamma is automatically tuned - see our latest paper\n",
        "            for more details (https://ieeexplore.ieee.org/document/9761414)\n",
        "    stats : either 'mean', 'max' or 'mean_max' to apply either global average pooling, global max pooling,\n",
        "            or both\n",
        "    conv_transpose : if false applies upsampling\n",
        "    \"\"\"\n",
        "\n",
        "    # Resize input to match number of channels for skip connections\n",
        "    resized_input = Conv2D(skip_connections.shape[-1], kernel_size=1, strides=(1, 1), padding='same', use_bias=True)(input)\n",
        "    # Resize skip connections to match image shape for input\n",
        "    resized_skip = Conv2D(skip_connections.shape[-1], kernel_size=1, strides=(2, 2), padding='same', use_bias=False)(skip_connections)\n",
        "\n",
        "    stride_x = resized_skip.shape[1] // input.shape[1]\n",
        "    stride_y = resized_skip.shape[2] // input.shape[2]\n",
        "\n",
        "    if conv_transpose:\n",
        "        resized_input = Conv2DTranspose(skip_connections.shape[-1], (stride_x, stride_y),strides=(stride_x, stride_y),padding='same')(resized_input)\n",
        "    else:\n",
        "        resized_input = UpSampling2D((stride_x,stride_y))(resized_input)\n",
        "\n",
        "    # element wise addition\n",
        "    added  = add([resized_input, resized_skip])\n",
        "\n",
        "    # perform non-linear activation\n",
        "    act = Activation('relu')(added)\n",
        "\n",
        "    # channel attention\n",
        "    channel_attention = channel_attention_block(act, stats)\n",
        "\n",
        "    # spatial attention\n",
        "    spatial_attention = spatial_attention_block(act, stats)\n",
        "\n",
        "    # combine channel and spatial weights\n",
        "    weights = multiply([channel_attention, spatial_attention])\n",
        "\n",
        "    # focal parameter for tuneable background suppression\n",
        "    if gamma:\n",
        "        weights = Gamma()(weights)\n",
        "\n",
        "    # rescale attention coefficient matrix to size of skip connection\n",
        "    stride_x_weights = skip_connections.shape[1] // weights.shape[1]\n",
        "    stride_y_weights = skip_connections.shape[2] // weights.shape[2]\n",
        "\n",
        "    # Upsample to match original skip connection resolution\n",
        "    if conv_transpose:\n",
        "        weights = Conv2DTranspose(skip_connections.shape[-1], (stride_x_weights, stride_y_weights), strides=(stride_x_weights, stride_y_weights), padding='same')(weights)\n",
        "    else:\n",
        "        weights = UpSampling2D((stride_x_weights, stride_y_weights))(weights)\n",
        "\n",
        "    # multiply skip connections by weights\n",
        "    weights = multiply([weights, skip_connections])\n",
        "\n",
        "    # perform final convolution and batch normalisation\n",
        "    output = Conv2D(skip_connections.shape[-1], kernel_size=1, strides=(1, 1), padding='same', use_bias=True)(weights)\n",
        "    output = BatchNormalization()(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Automatically tuned gamma parameter\n",
        "class Gamma(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Gamma, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        initializer = tf.keras.initializers.Ones()\n",
        "\n",
        "        self.w = self.add_weight(\n",
        "            shape=(1,1),\n",
        "            initializer=initializer,\n",
        "            trainable=True,\n",
        "            constraint= tf.keras.constraints.NonNeg())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = tf.clip_by_value(inputs, tf.keras.backend.epsilon(), 1.)\n",
        "        return (inputs)**self.w\n",
        "\n",
        "def generate_block(input_layer, filters, dropout_rate=0.2):\n",
        "    x = Conv2D(filters, (3, 3), padding='same', strides=1)(input_layer)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Conv2D(filters, (3, 3), padding='same', strides=1)(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    return x\n",
        "\n",
        "# Gating signal\n",
        "def GatingSignal(input, skip_connections):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : layer prior to upsampling\n",
        "    skip_connections : incoming skip connection to be refined\n",
        "    \"\"\"\n",
        "    signal = Conv2D(skip_connections.shape[-1], (1, 1), strides=(1, 1), padding=\"same\")(input)\n",
        "    signal = LeakyReLU(alpha=0.1)(signal)\n",
        "    signal = BatchNormalization()(signal)\n",
        "    return signal\n",
        "\n",
        "def spatial_kernel_size(input, beta=1, gamma=2):\n",
        "    \"\"\"\n",
        "    The original implementation based the kernel size on the channel, but with\n",
        "    square images, it can be simplified to:\n",
        "    k = | log2(R)/gamma + b/gamma|odd\n",
        "    \"\"\"\n",
        "\n",
        "    k = int(abs(np.log2((input.shape[1])/gamma) + beta/gamma))\n",
        "    out = k if k % 2 else k + 1\n",
        "\n",
        "    return out\n",
        "\n",
        "def channel_kernel_size(input, beta=1,gamma=2):\n",
        "    \"\"\"\n",
        "    k = | log2(C)/gamma + b/gamma|odd\n",
        "    \"\"\"\n",
        "    k = int(abs(np.log2(input.shape[-1]/gamma) + beta/gamma))\n",
        "    out = k if k % 2 else k + 1\n",
        "    return out\n",
        "\n",
        "def spatial_attention_block(input, stats):\n",
        "    \"\"\" Adaptive spatial attention block\n",
        "    \"\"\"\n",
        "\n",
        "    k_size = spatial_kernel_size(input)\n",
        "\n",
        "    # generate spatial statistics\n",
        "    if (stats == 'mean') or (stats == 'mean_max'):\n",
        "        mean = tf.reduce_mean(input, axis=-1, keepdims=True)\n",
        "        t = mean\n",
        "\n",
        "    if (stats == 'max') or (stats == 'mean_max'):\n",
        "        maximum = tf.reduce_max(input, axis=-1, keepdims=True)\n",
        "        t = maximum\n",
        "\n",
        "    if (stats == 'mean_max'):\n",
        "        t = concatenate([mean,maximum], axis=-1)\n",
        "\n",
        "    t = Conv2D(1, kernel_size=k_size, padding=\"same\",activation='sigmoid', use_bias = False)(t)\n",
        "\n",
        "    return t\n",
        "\n",
        "def channel_attention_block(input, stats):\n",
        "    \"\"\" Adaptive channel attention block\n",
        "    \"\"\"\n",
        "\n",
        "    k_size = channel_kernel_size(input)\n",
        "\n",
        "    # generate channel statistics\n",
        "    if (stats == 'mean') or (stats == 'mean_max'):\n",
        "        mean = tf.reduce_mean(input, axis=[1,2], keepdims=True)\n",
        "        mean = tf.squeeze(mean,axis=(-2))\n",
        "        mean = tf.transpose(mean,perm=[0,2,1])\n",
        "        t = mean\n",
        "\n",
        "    if (stats == 'max') or (stats == 'mean_max'):\n",
        "        maximum = tf.reduce_max(input, axis=[1,2], keepdims=True)\n",
        "        maximum = tf.squeeze(maximum,axis=(-2))\n",
        "        maximum = tf.transpose(maximum,perm=[0,2,1])\n",
        "        t = maximum\n",
        "\n",
        "    if (stats == 'mean_max'):\n",
        "        t = concatenate([mean,maximum], axis=-1)\n",
        "\n",
        "    t = Conv1D(filters=1, kernel_size=k_size, padding='same', use_bias=False)(t)\n",
        "    t = tf.transpose(t,perm=[0,2,1])\n",
        "    t = tf.expand_dims(t,(-2))\n",
        "    t = tf.math.sigmoid(t)\n",
        "\n",
        "    return t\n",
        "\n",
        "# def conv_layer_2D(input, neurons):\n",
        "\n",
        "#     conv1 = Conv2D(neurons, (3, 3), padding='same', activation='relu', strides=1)(input)\n",
        "#     conv1 = BatchNormalization()(conv1)\n",
        "#     conv2 = Conv2D(neurons, (3, 3), padding='same', activation='relu', strides=1)(conv1)\n",
        "#     out = BatchNormalization()(conv2)\n",
        "\n",
        "#     return out\n",
        "\n",
        "    # Then, replace BatchNormalization with InstanceNormalization in the conv_layer_2D function\n",
        "def conv_layer_2D(input, neurons, dropout_rate=0.2):\n",
        "    conv1 = Conv2D(neurons, (3, 3), padding='same', strides=1)(input)\n",
        "    conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Dropout(dropout_rate)(conv1)\n",
        "    conv2 = Conv2D(neurons, (3, 3), padding='same', strides=1)(conv1)\n",
        "    conv2 = LeakyReLU(alpha=0.1)(conv2)\n",
        "    out = tfa.layers.InstanceNormalization()(conv2)\n",
        "    out = Dropout(dropout_rate)(out)\n",
        "    conv3 = Conv2D(neurons, (3, 3), padding='same', strides=1)(out)\n",
        "    conv3 = LeakyReLU(alpha=0.1)(conv3)\n",
        "    out = BatchNormalization()(conv3)\n",
        "    out = Dropout(dropout_rate)(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "# U-Net model with MobileNetV2 backbone for comparison\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[288,384, 3], include_top=False)\n",
        "\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
        "\n",
        "down_stack.trainable = False\n",
        "\n",
        "def unet_model(output_channels:int):\n",
        "    inputs = tf.keras.layers.Input(shape=[288,384, 3])\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = down_stack(inputs)\n",
        "    x = skips[-1]\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "      x = up(x)\n",
        "      concat = tf.keras.layers.Concatenate()\n",
        "      x = concat([x, skip])\n",
        "      x = generate_block(x, output_channels)\n",
        "    # This is the last layer of the model\n",
        "    last = tf.keras.layers.Conv2DTranspose(\n",
        "        filters=output_channels, kernel_size=3, strides=2,\n",
        "        padding='same')  #64x64 -> 128x128\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# Focus U-Net model with MobileNetV2 backbone\n",
        "def focus_unet_model(output_channels:int):\n",
        "    feature_map = [32, 64, 128, 256, 512]\n",
        "    inputs = tf.keras.layers.Input(shape=[288,384, 3])\n",
        "    contracting_convs = down_stack(inputs)\n",
        "    cnn_chain = contracting_convs[-1]\n",
        "    contracting_convs = reversed(contracting_convs[:-1])\n",
        "    for skip_connection, filters in zip(contracting_convs, reversed(feature_map[:-1])):\n",
        "        cnn_chain = Conv2DTranspose(filters, (2, 2), strides=(2, 2),padding='same')(cnn_chain)\n",
        "        cnn_chain = concatenate([cnn_chain, skip_connection], axis=-1)\n",
        "        cnn_chain = conv_layer_2D(cnn_chain, filters)\n",
        "        cnn_chain = Conv2D(filters, (3, 3), padding='same', strides=1)(cnn_chain)\n",
        "        cnn_chain = LeakyReLU(alpha=0.1)(cnn_chain)\n",
        "        cnn_chain = BatchNormalization()(cnn_chain)\n",
        "    last = tf.keras.layers.Conv2DTranspose(\n",
        "        filters=output_channels, kernel_size=3, strides=2,\n",
        "        padding='same')\n",
        "    x = last(cnn_chain)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7orkKkZJBDoy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import metrics\n",
        "model = focus_unet_model(2)\n",
        "adm = Adam(learning_rate=1e-3)\n",
        "model.compile(loss=focalLoss(gamma=best_gamma), optimizer=adm, metrics=['accuracy',iou_metric])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGxEl0ZFBHFg"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images,train_masks_cat,\n",
        "             batch_size=4,\n",
        "             epochs=12,\n",
        "             validation_data=(valid_images,valid_masks_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X46XjAY4BMJW"
      },
      "outputs": [],
      "source": [
        "test_predictions = model.predict(test_images)\n",
        "test_pred_classes = np.argmax(test_predictions, axis=-1)\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "\n",
        "# Flatten the arrays\n",
        "true = test_masks.flatten()\n",
        "pred = test_pred_classes.flatten()\n",
        "\n",
        "# Compute metrics\n",
        "accuracy = accuracy_score(true, pred)\n",
        "f1 = f1_score(true, pred)\n",
        "precision = precision_score(true, pred)\n",
        "recall = recall_score(true, pred)\n",
        "auc = roc_auc_score(true, pred)\n",
        "\n",
        "# For IoU, we can use tf.keras.metrics\n",
        "m = MeanIoU(num_classes=2)\n",
        "m.update_state(true, pred)\n",
        "iou = m.result().numpy()\n",
        "\n",
        "print('Accuracy: ', accuracy)\n",
        "print('F1 score: ', f1)\n",
        "print('Precision: ', precision)\n",
        "print('Recall: ', recall)\n",
        "print('AUC: ', auc)\n",
        "print('IoU: ', iou)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McPzRFERBQc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed9d2a7-45fe-476b-d4a5-ae5aaa7b7007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 236ms/step\n"
          ]
        }
      ],
      "source": [
        "test_predictions = model.predict(test_images)\n",
        "test_pred_classes = np.argmax(test_predictions, axis=-1)\n",
        "\n",
        "# Flatten the arrays\n",
        "t = test_masks.flatten()\n",
        "p = test_pred_classes.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zaQjy1lBSm6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "predict = model.predict(test_images)\n",
        "# Flatten the arrays\n",
        "t = test_masks.flatten()\n",
        "p = test_pred_classes.flatten()\n",
        "\n",
        "def report(y_true, y_pred):\n",
        "    print('\\n        ----------Test Data------------------')\n",
        "    print('Accuracy: {:,.2f}'.format(accuracy_score(y_true, y_pred )* 100))\n",
        "    print('Precision: {:,.2f}'.format(precision_score(y_true, y_pred, average='macro') * 100))\n",
        "    print('Recall-score: {:,.2f}'.format(recall_score(y_true, y_pred, average='macro') * 100))\n",
        "    print('F1-score: {:,.2f}'.format(f1_score(y_true, y_pred, average='macro') * 100))\n",
        "    print('AUC-score: {:,.2f}'.format(roc_auc_score(y_true, y_pred) * 100))\n",
        "    # For IoU, we can use tf.keras.metrics\n",
        "    m = MeanIoU(num_classes=2)\n",
        "    m.update_state(y_true, y_pred)\n",
        "    iou = m.result().numpy()\n",
        "    print('IoU-score: {:,.2f}'.format(iou*100))\n",
        "\n",
        "report(t,p)\n",
        "\n",
        "\n",
        "# Accuracy: 98.12\n",
        "# Precision: 94.38\n",
        "# Recall-score: 93.88\n",
        "# F1-score: 94.13\n",
        "# AUC-score: 93.88\n",
        "# IoU-score: 97.31"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}